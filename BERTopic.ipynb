{
 "cells": [
  {
   "cell_type": "code",
   "id": "4027a24c83f01b84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T21:26:34.721501Z",
     "start_time": "2025-03-30T21:26:14.940201Z"
    }
   },
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import sys\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import HDBSCAN\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "umap_model = UMAP(n_components=5, n_neighbors=50, random_state=42, metric=\"cosine\", verbose=True)\n",
    "hdbscan_model = HDBSCAN(min_samples=20, gen_min_span_tree=True, min_cluster_size=1500, verbose=True, prediction_data=True)\n",
    "topic_model = BERTopic(embedding_model=embedding_model,\n",
    "                       umap_model=umap_model,\n",
    "                       hdbscan_model=hdbscan_model,\n",
    "                       verbose=True, \n",
    "                       calculate_probabilities=True,\n",
    "                       nr_topics='auto')\n",
    "\n",
    "training_df = pd.read_feather('train.feather')\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-30 18:26:31.269] [CUML] [info] build_algo set to brute_force_knn because random_state is given\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "959f951de20a2bcf",
   "metadata": {},
   "source": "Uncomment to create the window"
  },
  {
   "cell_type": "code",
   "id": "28e4d09b0a0fc38e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T21:28:29.123136Z",
     "start_time": "2025-03-30T21:26:34.722721Z"
    }
   },
   "source": [
    "n = 5\n",
    "training_df['combined_text'] = [' '.join(training_df['text'].iloc[i:i+n+1]) for i in range(len(training_df))]\n",
    "training_df['expected'] = [np.mean(training_df['sponsored'].iloc[i:i+n+1]) for i in range(len(training_df))]\n",
    "texts = training_df['combined_text'].tolist()\n",
    "expected = training_df['expected'].tolist()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "1721fdcb3c339d20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T21:28:29.127403Z",
     "start_time": "2025-03-30T21:28:29.124264Z"
    }
   },
   "source": [
    "def text_rolling_window_generator(input_df, window_size, batch_size=1000):\n",
    "    \"\"\" Generator that yields rolling window samples in batches. \"\"\"\n",
    "    \n",
    "    batch_X, batch_y = [], []\n",
    "\n",
    "    for doc_id in input_df['videoID'].unique():\n",
    "        doc_sentences = input_df[input_df['videoID'] == doc_id]\n",
    "        topics = doc_sentences['text'].tolist()\n",
    "        labels_array = doc_sentences['sponsored'].values\n",
    "\n",
    "        for i in range(len(doc_sentences) - window_size + 1):\n",
    "            window_topics = ' '.join(topics[i:i+window_size])\n",
    "            window_label = np.mean(labels_array[i:i+window_size])  # Soft label\n",
    "            \n",
    "            batch_X.append(window_topics)\n",
    "            batch_y.append(window_label)\n",
    "\n",
    "    if batch_X:  # Yield any remaining data\n",
    "        return np.array(batch_X), np.array(batch_y)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "aa747b281544c974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T21:28:29.136822Z",
     "start_time": "2025-03-30T21:28:29.128917Z"
    }
   },
   "source": [
    "# X_train, Y_train = text_rolling_window_generator(training_df, 5)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Uncomment this code to recalculate the embeddings (takes about 20 mins)",
   "id": "62756662a7563d6f"
  },
  {
   "cell_type": "code",
   "id": "9cdd04a9f4be35e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T21:28:29.146522Z",
     "start_time": "2025-03-30T21:28:29.137808Z"
    }
   },
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "# \n",
    "# # Create embeddings\n",
    "# emb_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# embeddings = emb_model.encode(texts, show_progress_bar=True)\n",
    "# \n",
    "# with open('embeddings.npy', 'wb') as f:\n",
    "#     np.save(f, embeddings)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "95ae2fc86acd749c",
   "metadata": {},
   "source": [
    "Topic Model Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "95de550a0a184a58",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-03-30T21:28:29.147569Z"
    }
   },
   "source": [
    "import pickle\n",
    "\n",
    "embeddings = np.load('embeddings.npy')\n",
    "\n",
    "topic_model = topic_model.fit(texts, y=expected, embeddings=embeddings)\n",
    "    \n",
    "# with open('BERT_Topic_list.pkl', 'wb') as f:\n",
    "#     pickle.dump(topics, f)\n",
    "\n",
    "# with open('BERT_Topic_probs.pkl', 'wb') as f:\n",
    "#     pickle.dump(probs, f)\n",
    "#     \n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 18:28:53,025 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-30 18:41:14.141] [CUML] [debug] Performing categorical intersection\n",
      "[2025-03-30 18:44:49.992] [CUML] [debug] Running transform\n",
      "[2025-03-30 18:44:49.992] [CUML] [debug] Building KNN Graph\n",
      "[2025-03-30 18:56:59.306] [CUML] [debug] Smoothing KNN distances\n",
      "[2025-03-30 18:56:59.361] [CUML] [debug] Executing fuzzy simplicial set\n",
      "[2025-03-30 18:56:59.889] [CUML] [debug] Performing L1 normalization\n",
      "[2025-03-30 18:57:20.847] [CUML] [debug] n_epochs=30\n",
      "[2025-03-30 18:57:43.705] [CUML] [debug] Computing # of epochs for training each sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:03:16,058 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-03-30 19:03:16,187 - BERTopic - Cluster - Start clustering the reduced embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-03-30 18:57:44.168] [CUML] [debug] Performing optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 19:25:52,617 - BERTopic - Cluster - Completed ✓\n",
      "2025-03-30 19:25:52,618 - BERTopic - Representation - Extracting topics using c-TF-IDF for topic reduction.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topic_model.save(\n",
    "    path='./TopicModel_1500',\n",
    "    serialization=\"safetensors\",\n",
    "    save_ctfidf=True,\n",
    "    save_embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ],
   "id": "bd0a29eaeda6c76e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "29a15784830c22cb",
   "metadata": {},
   "source": [
    "# with open('combined_training.pkl', 'wb') as f:\n",
    "#     pickle.dump(texts, f)\n",
    "#     \n",
    "# with open('expected_training.pkl', 'wb') as f:\n",
    "#     pickle.dump(expected, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "topic_model.get_topic_info()",
   "id": "2e58feb1d878b488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# test = topic_model.transform(texts[:5])",
   "id": "500f6ece5f1f9905",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fbc1ea31f26f75a3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
